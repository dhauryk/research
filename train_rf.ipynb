{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, make_scorer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17698/7997590.py:2: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/dhauryk/!DUNAI/train_ver2.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df = df.sort_values([\"ncodpers\", \"fecha_dato\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target columns (product subscriptions)\n",
    "target_cols = [col for col in df.columns if col.startswith(\"ind_\")]\n",
    "target_cols.append(\"ncodpers\") \n",
    "\n",
    "# Feature columns (customer attributes)\n",
    "feature_cols = [\"ind_empleado\", \"pais_residencia\", \"sexo\", \"age\", \"ind_nuevo\", \"antiguedad\", \"nomprov\", \"segmento\"]\n",
    "\n",
    "dtype_list = {\"ncodpers\": \"int64\"}\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"ind_\"):\n",
    "        dtype_list.setdefault(col, \"float16'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing function\n",
    "def preprocess_data(df, feature_cols, target_cols, dtype_list):\n",
    "    train = df\n",
    "    \n",
    "    # Preprocessing logic here\n",
    "    for col in feature_cols:\n",
    "        if col == 'age':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df.loc[df.age < 18, \"age\"] = df.loc[(df.age >= 18) & (df.age <= 30), \"age\"].mean(skipna=True)\n",
    "            df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "            df['age'] = df['age'].astype(int)\n",
    "        \n",
    "        elif col == 'ind_nuevo':\n",
    "            df.loc[df[col].isnull(), col] = 1\n",
    "        \n",
    "        elif col == 'antiguedad':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df.loc[df[col].isnull(), col] = df[col].min()\n",
    "            df.loc[df[col] < 0, col] = 0\n",
    "        \n",
    "        elif col == 'nomprov':\n",
    "            df[col].fillna('Unknown', inplace=True)\n",
    "        \n",
    "        elif col == 'segmento':\n",
    "            df[col] = df[col].apply(lambda x: str(x).split('-')[0])\n",
    "            df.loc[df[col].isnull(), col] = 'Unknown'\n",
    "        \n",
    "        else:\n",
    "            print(col)\n",
    "            df[col].fillna(-999, inplace=True)\n",
    "    \n",
    "    # Label encoding for categorical columns\n",
    "    for col in feature_cols:\n",
    "        if df[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            le.fit(list(df[col].values))\n",
    "            df[col] = le.transform(df[col].values)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col].fillna(-999, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_empleado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17698/2847176983.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(-999, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pais_residencia\n",
      "sexo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17698/2847176983.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['age'].fillna(df['age'].mean(), inplace=True)\n",
      "/tmp/ipykernel_17698/2847176983.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('Unknown', inplace=True)\n",
      "/tmp/ipykernel_17698/2847176983.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(-999, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_data(df, feature_cols, target_cols, dtype_list)\n",
    "# Separate features (X) and target (y) from the training data\n",
    "X = data[feature_cols]\n",
    "y = data[target_cols[1:]]  # excluding 'ncodpers'\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define the custom scorer using make_scorer\n",
    "def map7_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)\n",
    "    top_k_preds = np.argsort(y_pred, axis=1)[:, -7:]  # Get top 7 predictions\n",
    "    actuals = [set(np.where(row == 1)[0]) for row in y]  # Convert y into sets of actual labels\n",
    "    \n",
    "    return map7(top_k_preds, actuals)\n",
    "\n",
    "# Create the custom scorer\n",
    "map7_scorer_obj = make_scorer(map7_scorer, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Initialize RandomForest model\n",
    "clf = RandomForestClassifier(n_estimators=1, max_depth=10, n_jobs=10, verbose=True, random_state=42)\n",
    "\n",
    "# Cross-validation: We will use StratifiedKFold for multi-label classification\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation score for RandomForestClassifier\n",
    "cross_val_score_rf = cross_val_score(clf, x_train, y_train, cv=cv, scoring=map7_scorer_obj)\n",
    "\n",
    "# Training the model\n",
    "clf.fit(x_train, y_train, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importance\n",
    "feature_importance = clf.feature_importances_\n",
    "sns.barplot(x=feature_cols, y=feature_importance)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction and MAP7 calculation\n",
    "k = 7\n",
    "y_pred_prob = clf.predict_proba(x_test)\n",
    "top_k_preds = np.argsort(y_pred, axis=1)[:, -k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map7(preds, actuals, k=7):\n",
    "    avg_precisions = []  # Сюда собираем средние точности каждой последовательности\n",
    "    for pred, actual in zip(preds, actuals):\n",
    "        match = 0  # Счетчик совпадений\n",
    "        sum_precisions = 0  # Сумма точности в каждом ранге\n",
    "        for i, p in enumerate(pred[:k]):  # Берем топ 7\n",
    "            if p in actual:  # Проверяем есть ли прогноз в актуальном списке\n",
    "                match += 1\n",
    "                sum_precisions += match / (i + 1)  # Точность вычисления на i-м ранге\n",
    "        avg_precisions.append(sum_precisions / min(k, len(actual)))  # Считаем среднюю точность\n",
    "\n",
    "    return np.mean(avg_precisions)  # Возвращаем среднее значения всех средних значений точности\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAP7 on the validation set\n",
    "actuals = []  # This should be your test set actual labels\n",
    "for idx, row in enumerate(test_labels):  # Modify this to fit your actual label format\n",
    "    actual = set(np.where(row == 1)[0])  # Extract the indices of true labels\n",
    "    actuals.append(actual)\n",
    "    \n",
    "map7_score = map7(top_k_preds, actuals, k)\n",
    "print(f'MAP@7 Score: {map7_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define target columns and dtypes\n",
    "targetcols = ['ncodpers', 'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "# Data preprocessing function\n",
    "def preprocess_data(train_file, test_file, feature_cols, targetcols, dtype_list):\n",
    "    train = pd.read_csv(train_file, usecols=feature_cols + targetcols, dtype=dtype_list)\n",
    "    test = pd.read_csv(test_file, usecols=feature_cols, dtype=dtype_list)\n",
    "    \n",
    "    # Preprocessing logic here\n",
    "    for col in feature_cols:\n",
    "        if col == 'age':\n",
    "            train[col] = pd.to_numeric(train[col], errors='coerce')\n",
    "            test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "            train.loc[train.age < 18, \"age\"] = train.loc[(train.age >= 18) & (train.age <= 30), \"age\"].mean(skipna=True)\n",
    "            test.loc[test.age > 100, \"age\"] = test.loc[(test.age >= 30) & (test.age <= 100), \"age\"].mean(skipna=True)\n",
    "            train['age'].fillna(train['age'].mean(), inplace=True)\n",
    "            test['age'].fillna(test['age'].mean(), inplace=True)\n",
    "            train['age'] = train['age'].astype(int)\n",
    "            test['age'] = test['age'].astype(int)\n",
    "        \n",
    "        elif col == 'ind_nuevo':\n",
    "            train.loc[train[col].isnull(), col] = 1\n",
    "            test.loc[test[col].isnull(), col] = 1\n",
    "        \n",
    "        elif col == 'antiguedad':\n",
    "            train[col] = pd.to_numeric(train[col], errors='coerce')\n",
    "            test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "            train.loc[train[col].isnull(), col] = train[col].min()\n",
    "            test.loc[test[col].isnull(), col] = test[col].min()\n",
    "            train.loc[train[col] < 0, col] = 0\n",
    "            test.loc[test[col] < 0, col] = 0\n",
    "        \n",
    "        elif col == 'nomprov':\n",
    "            train[col].fillna('Unknown', inplace=True)\n",
    "            test[col].fillna('Unknown', inplace=True)\n",
    "        \n",
    "        elif col == 'segmento':\n",
    "            train[col] = train[col].apply(lambda x: str(x).split('-')[0])\n",
    "            test[col] = test[col].apply(lambda x: str(x).split('-')[0])\n",
    "            train.loc[train[col].isnull(), col] = 'Unknown'\n",
    "            test.loc[test[col].isnull(), col] = 'Unknown'\n",
    "        \n",
    "        else:\n",
    "            train[col].fillna(-999, inplace=True)\n",
    "            test[col].fillna(-999, inplace=True)\n",
    "    \n",
    "    # Label encoding for categorical columns\n",
    "    for col in feature_cols:\n",
    "        if train[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            le.fit(list(train[col].values) + list(test[col].values))\n",
    "            train[col] = le.transform(train[col].values)\n",
    "            test[col] = le.transform(test[col].values)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_file = '../input/train_ver2.csv'\n",
    "test_file = '../input/test_ver2.csv'\n",
    "feature_cols = [\"ind_empleado\",\"pais_residencia\",\"sexo\", \"age\", \"ind_nuevo\", \"antiguedad\", \"nomprov\", \"segmento\"]\n",
    "dtype_list = {'ind_cco_fin_ult1': 'float16', 'ind_deme_fin_ult1': 'float16', 'ind_aval_fin_ult1': 'float16',\n",
    "              'ind_valo_fin_ult1': 'float16', 'ind_reca_fin_ult1': 'float16', 'ind_ctju_fin_ult1': 'float16',\n",
    "              'ind_cder_fin_ult1': 'float16', 'ind_plan_fin_ult1': 'float16', 'ind_fond_fin_ult1': 'float16',\n",
    "              'ind_hip_fin_ult1': 'float16', 'ind_pres_fin_ult1': 'float16', 'ind_nomina_ult1': 'float16',\n",
    "              'ind_cno_fin_ult1': 'float16', 'ncodpers': 'int64', 'ind_ctpp_fin_ult1': 'float16',\n",
    "              'ind_ahor_fin_ult1': 'float16', 'ind_dela_fin_ult1': 'float16', 'ind_ecue_fin_ult1': 'float16',\n",
    "              'ind_nom_pens_ult1': 'float16', 'ind_recibo_ult1': 'float16', 'ind_deco_fin_ult1': 'float16',\n",
    "              'ind_tjcr_fin_ult1': 'float16', 'ind_ctop_fin_ult1': 'float16', 'ind_viv_fin_ult1': 'float16',\n",
    "              'ind_ctma_fin_ult1': 'float16'}\n",
    "\n",
    "train, test = preprocess_data(train_file, test_file, feature_cols, targetcols, dtype_list)\n",
    "\n",
    "# Separate features (X) and target (y) from the training data\n",
    "X = train[feature_cols]\n",
    "y = train[targetcols[1:]]  # excluding 'ncodpers'\n",
    "\n",
    "# Split data into train and validation sets (80-20 split)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomForest model\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Cross-validation: We will use StratifiedKFold for multi-label classification\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation score for RandomForestClassifier\n",
    "cross_val_score_rf = cross_val_score(clf, x_train, y_train, cv=cv, scoring='average_precision_score')\n",
    "\n",
    "# Training the model\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Plotting feature importance\n",
    "feature_importance = clf.feature_importances_\n",
    "sns.barplot(x=feature_cols, y=feature_importance)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Prediction and MAP7 calculation\n",
    "y_pred_prob = clf.predict_proba(x_test)\n",
    "\n",
    "# Compute MAP7: Mean Average Precision at 7\n",
    "def map_at_k(y_true, y_pred_prob, k=7):\n",
    "    avg_precision = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        true_labels = np.where(y_true[i] == 1)[0]  # ground truth labels\n",
    "        pred_labels = np.argsort(y_pred_prob[i])[::-1][:k]  # top k predicted labels\n",
    "        avg_precision.append(average_precision_score([true_labels], [pred_labels]))  # AP score per instance\n",
    "    return np.mean(avg_precision)\n",
    "\n",
    "# Calculate MAP7 on the validation set\n",
    "map7_score = map_at_k(y_test.values, y_pred_prob)\n",
    "print(f'MAP@7 Score: {map7_score:.4f}')\n",
    "\n",
    "# Final predictions on the test set\n",
    "y_test_prob = clf.predict_proba(test[feature_cols])\n",
    "\n",
    "# Generate top 7 predictions for the test dataset\n",
    "test_ids = test['ncodpers'].values\n",
    "final_preds = []\n",
    "for idx, pred in enumerate(y_test_prob):\n",
    "    top_k = np.argsort(pred)[::-1][:7]\n",
    "    final_preds.append(\" \".join(targetcols[1:][top_k]))  # Map the indices to product names\n",
    "\n",
    "# Prepare the submission\n",
    "submission = pd.DataFrame({'ncodpers': test_ids, 'added_products': final_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
