{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Для работы core необходимо в Open Workspace Settings (JSON) вставить строку \"python.analysis.extraPaths\": [\"${workspaceFolder}/utils/\"]\n",
    "В скриптах, где будет использоваться core необходимо перед импортом добавлять строки:\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"utils\"))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "IMAGE_EXTENSIONS = {'.tiff', '.tif', '.jpeg', '.jpg', '.jpe', '.bmp', '.png'}\n",
    "\n",
    "def is_image_file(filename:str):\n",
    "    \"\"\"\n",
    "    Проверяем, что файл является изображением. \n",
    "    В данный момент протестированы только данные форматы файлов изображений.\n",
    "    :param filename: полный путь к файлу\n",
    "    :return: True - если файл является изображением\n",
    "    \"\"\"\n",
    "    _, file_extension = os.path.splitext(filename)\n",
    "    return file_extension in IMAGE_EXTENSIONS\n",
    "\n",
    "\n",
    "def calculate_count_file_extensions(folder: str):\n",
    "    \"\"\"\n",
    "    Функция возвращает словарь, где в качестве ключа выступает расширение файла, а в качестве значение количество файлов с таким расширением\n",
    "    :param folder: папка, для которой будут искать все возможные расширения файлов, включая вложенные\n",
    "    :return: Возвращает словарь, где в качестве ключа выступают расширения, а в качестве значения - количества\n",
    "    \"\"\"\n",
    "    \n",
    "    exts = dict()\n",
    "    with os.scandir(folder) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_dir():\n",
    "                sub_exts = calculate_count_file_extensions(entry.path)\n",
    "                for ext_key in sub_exts:\n",
    "                    if ext_key not in exts.keys():\n",
    "                        exts[ext_key] = 0\n",
    "                    exts[ext_key] += sub_exts[ext_key]\n",
    "                \n",
    "            elif entry.is_file():\n",
    "                ext_key = str.lower(os.path.splitext(entry.name)[1])\n",
    "                if ext_key not in exts.keys():\n",
    "                    exts[ext_key] = 0\n",
    "                exts[ext_key] += 1\n",
    "    \n",
    "    return exts     # Возвращаем набор расширений всех файлов в этой папке\n",
    "\n",
    "\n",
    "def get_count_image_files(folder: str):\n",
    "    \"\"\"\n",
    "    Определяет, сколько файлов изображения содержит папка.\n",
    "    :param folder: имя папки, для которой будет подсчитано количество файлов, в том числе и во вложенных папках\n",
    "    :return: Возвращает количество файлов изображений внутри папки, включая и вложенные.\n",
    "    \"\"\"\n",
    "    return len(get_all_image_file_names_in_folder(folder))   # получаем имена файлов изображений и папок, внутри папки folder\n",
    "\n",
    "\n",
    "def get_all_image_file_names_in_folder(folder:str):\n",
    "    \"\"\"\n",
    "    Возвращает список всех имён (путей) файлов изображений, находящихся в папке folder, а тажке во всех вложенных на всех уровнях.\n",
    "    Рекурсивная функция\n",
    "    :param folder: имя папки верхнего уровня, для которой нужно найти все вложенные файлы изображений, включая и во вложенных файлах\n",
    "    :return: Возвращает список путей к файлам изображений, которые находятся внутри папки folder на всех вложенных уровнях.\n",
    "    \"\"\"\n",
    "    tuple_extentions = tuple(IMAGE_EXTENSIONS)\n",
    "    return get_all_files_with_specific_extentions(folder, tuple_extentions)\n",
    "    \n",
    "\n",
    "def get_all_files_with_specific_extentions(folder:str, extentions: tuple):\n",
    "    \"\"\"\n",
    "    Возвращает список всех имён (путей) файлов изображений, находящихся в папке folder, а тажке во всех вложенных на всех уровнях.\n",
    "    Рекурсивная функция\n",
    "    :param folder: имя папки верхнего уровня, для которой нужно найти все вложенные файлы изображений, включая и во вложенных файлах\n",
    "    :extentions: список расширений файлов, которые нужно найти, например [\".jpg\", \".jpeg\"]\n",
    "    :return: Возвращает список путей к файлам изображений, которые находятся внутри папки folder на всех вложенных уровнях.\n",
    "    \"\"\"\n",
    "    result_list = list()\n",
    "    with os.scandir(folder) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_dir():\n",
    "                result_list.extend(get_all_files_with_specific_extentions(entry.path, extentions))\n",
    "            elif str.lower(entry.name).endswith(extentions) and entry.is_file():\n",
    "                result_list.append(entry.path)\n",
    "\n",
    "    return result_list\n",
    "\n",
    "def get_file_name_only(file_path: str):\n",
    "    return file_path.split(os.sep)[-1][::-1].split('.', 1)[1][::-1]\n",
    "\n",
    "def get_file_guid(file_path: str):\n",
    "    return file_path.split(os.sep)[-1][::-1].split('.', 1)[1][::-1][:36]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено 0 изображений\n",
      "Добавлено 0 изображений\n",
      "На создание/ обновление бокса потребовалось -0.10820364952087402\n",
      "Бокс обновлен, начинаем поиск похожих изображений\n",
      "На поиск похожих изображений потребовалось -3.2875211238861084\n",
      "Тест активирован. Сохраняем изображения для визуального контроля\n",
      "На сохранение похожих изображений в соответствующие лучшему изображению папки потребовалось -0.043355703353881836\n",
      "На сохранение похожих изображений в соответствующие лучшему изображению папки и их склейку потребовалось -4.76837158203125e-07\n",
      "Завершено\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Скрипт для поиска похожих изображений (не байтовых дубликатов)\n",
    "    Основная функция принимает путь папке с базой изображений, путь к папке для сохранения результатов, минимальную и максимальную дистанцию, флаг для теста.\n",
    "    Если нашлись похожие изображения, то после работы скрипта создается папка с json. В json изображения отсортированы по количеству похожих в порядке убывания.\n",
    "    В каждом словаре похожих изображений заглавным является изображение с самым большим весом в KB.\n",
    "    При активации теста создаются папки, чье имя == имени изображения с самым большим весом в KB. В этой папке хранится лучшее изображение и все похожие на него.\n",
    "    Так же при активации теста создается папка, в которой сохраняются папки, чье имя == имени изображения с самым большим весом в KB. Но в них хранятся склеенные\n",
    "    изображения с логикой: лучшее изображение склеено с каждым похожим. Именем изображения является дистанция между векторами каждой пары.\n",
    "    Для поиска подходящий дистанций реализована возможность вызова основной функции ступенчато. После каждой стапени создается папка с указанием диапазона дистанции.\n",
    "\n",
    "    Папка с результатом поиска очищается при каждом новом запуске скрипта.\n",
    "    \n",
    "\"\"\"\n",
    "# git clone https://github.com/sebastian-sz/efficientnet-v2-keras.git \n",
    "\n",
    "from keras.applications import NASNetLarge\n",
    "from keras.applications.nasnet import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import pickle as pk\n",
    "from PIL import Image\n",
    "from sklearn.metrics import DistanceMetric\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "\n",
    "#функция для преобразования изображения в вектор\n",
    "def build_vector(img, model):\n",
    "    np_img = np.array(img.resize((331, 331), Image.LANCZOS))\n",
    "    preprocessed_img = preprocess_input(np.expand_dims(np_img, axis = 0))\n",
    "    x_conv = model.predict(preprocessed_img)\n",
    "    img_vector = x_conv[0]\n",
    "    img_vector /=  np.linalg.norm(img_vector)\n",
    "\n",
    "    return img_vector\n",
    "\n",
    "\n",
    "def glue_image(path_result, model, dist):\n",
    "    all_folder_similar = os.listdir(path_result)\n",
    "    all_folder_similar.remove('result_duplicate-similar.json')\n",
    "\n",
    "    for folder_similar in all_folder_similar:\n",
    "        os.makedirs(os.path.join(path_result, \"!result_glue\", folder_similar), exist_ok=True)\n",
    "\n",
    "        all_img_in_folder = os.listdir(os.path.join(path_result, folder_similar))\n",
    "        all_img_guid_in_folder = [img_name.split('.')[0] for img_name in all_img_in_folder]\n",
    "        best_img = all_img_in_folder[all_img_guid_in_folder.index(folder_similar)]\n",
    "        list_similar_img = [img for img in all_img_in_folder if img.split('.')[0] != best_img.split('.')[0]]\n",
    "\n",
    "        best_image = Image.open(os.path.join(path_result, folder_similar, best_img))\n",
    "                \n",
    "        if best_image.mode != 'RGB':\n",
    "            best_image = best_image.convert('RGB')\n",
    "            best_image = ImageOps.exif_transpose(best_image)\n",
    "\n",
    "        best_image_vector = build_vector(best_image, model)\n",
    "\n",
    "        for similar_img in list_similar_img:\n",
    "            two_img_vector = [best_image_vector]\n",
    "\n",
    "            similar_image = Image.open(os.path.join(path_result, folder_similar, similar_img))\n",
    "            similar_image = ImageOps.exif_transpose(similar_image)\n",
    "            \n",
    "            if similar_image.mode != 'RGB':\n",
    "                similar_image = similar_image.convert('RGB')\n",
    "\n",
    "            similar_image_vector = build_vector(similar_image, model)\n",
    "            two_img_vector.append(similar_image_vector)\n",
    "\n",
    "            two_img_vector = np.array(two_img_vector)\n",
    "            two_img_vector = np.squeeze(two_img_vector)\n",
    "\n",
    "            name_dist = str(dist.pairwise(two_img_vector)[0][1]).replace('.', ',')\n",
    "\n",
    "            best_image_size = best_image.size\n",
    "            new_image = Image.new('RGB',(2 * best_image_size[0], best_image_size[1]), (250,250,250))\n",
    "            \n",
    "            new_image.paste(best_image, (0, 0))\n",
    "            new_image.paste(similar_image, (best_image_size[0], 0))\n",
    "\n",
    "            new_image.save((os.path.join(path_result, \"!result_glue\", folder_similar, f\"{name_dist}.jpg\")), \"JPEG\")\n",
    "\n",
    "\n",
    "def save_similar(path_result, list_path_all_img, result_dict_all_sort, all_img_guid):\n",
    "    print(\"Тест активирован. Сохраняем изображения для визуального контроля\")\n",
    "\n",
    "    for path in list_path_all_img:\n",
    "        name_img = os.path.basename(path).split('.')[0]\n",
    "        if name_img in result_dict_all_sort.keys():\n",
    "            path_best_img = os.path.join(path_result, os.path.basename(path).split('.')[0])\n",
    "            os.makedirs(path_best_img, exist_ok=True)\n",
    "            pref = list_path_all_img[all_img_guid.index(os.path.basename(path).split('.')[0])].split('/')[-2]\n",
    "            path_for_save = os.path.join(path_best_img, pref)\n",
    "            if os.path.exists(path_for_save) == False:\n",
    "                os.makedirs(path_for_save, exist_ok=True)\n",
    "            shutil.copy2(path, path_for_save)\n",
    "            \n",
    "            all_similar = []\n",
    "            all_pref = []\n",
    "\n",
    "            for similar in result_dict_all_sort[name_img]:\n",
    "                all_similar.append(all_img_guid.index(similar))\n",
    "                all_pref.append(list_path_all_img[all_img_guid.index(similar)].split('/')[-2])\n",
    "            \n",
    "            for i in range(len(all_similar)):\n",
    "                path_for_save = os.path.join(path_best_img, all_pref[i])\n",
    "                if os.path.exists(path_for_save) == False:\n",
    "                    os.makedirs(path_for_save, exist_ok=True)\n",
    "                shutil.copy2(list_path_all_img[all_similar[i]], path_for_save)\n",
    "\n",
    "\n",
    "def find_similar(basepath, path_result, dist_min, dist_max, test):\n",
    "            \n",
    "    model = NASNetLarge(weights='imagenet', input_shape=(331, 331, 3), include_top = False, pooling = 'max')\n",
    "\n",
    "    if os.path.exists(path_result):\n",
    "        shutil.rmtree(path_result, ignore_errors=True)\n",
    "    os.makedirs(path_result, exist_ok=True)\n",
    "\n",
    "    list_path_all_img = get_all_image_file_names_in_folder(basepath)\n",
    "    all_img_guid = [os.path.basename(img_path).split('.')[0] for img_path in list_path_all_img]\n",
    "    all_img_unique_guid = set(all_img_guid)\n",
    "\n",
    "    start_box = time.time()\n",
    "\n",
    "    try:\n",
    "        all_img_vector_and_guid = pk.load(open(\"cache_data\\\\box_vector_NASNetLarge.pkl\", \"rb\"))\n",
    "    except (OSError, IOError) as exc:\n",
    "        all_img_vector_and_guid = []\n",
    "    \n",
    "    list_for_check = [img['img_guid'].split('.')[0] for img in all_img_vector_and_guid]           #список guid всех изображений в базе\n",
    "    list_for_delet = []                                                     #список кондидатов на удаление из бокса\n",
    "\n",
    "    for idx in range(len(all_img_vector_and_guid)):                                    #ищем изображения, которые есть в боксе, но нету в базе\n",
    "        if all_img_vector_and_guid[idx]['img_guid'].split('.')[0] not in all_img_unique_guid:\n",
    "            list_for_delet.append(idx)\n",
    "\n",
    "    print(f\"Удалено {len(list_for_delet)} изображений\")\n",
    "\n",
    "    for idx in reversed(list_for_delet):                                      #удаляем изображения из бокса, которые есть в боксе, но нету в базе\n",
    "        del all_img_vector_and_guid[idx]\n",
    "\n",
    "    new_img = 0\n",
    "\n",
    "    for path_img in list_path_all_img:                                      #проходим по всем изображениям в базе\n",
    "        img_guid = os.path.basename(path_img).split('.')[0]\n",
    "        if img_guid in list_for_check:                                      #добавляем все guid и их вектора изображений из базы в бокс, если их нету в боксе\n",
    "            continue\n",
    "        img = Image.open(path_img)\n",
    "        img = ImageOps.exif_transpose(img)\n",
    "        \n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        img_vector = build_vector(img, model)\n",
    "        new_img += 1\n",
    "\n",
    "        all_img_vector_and_guid.append({'img_guid': img_guid, 'vector': img_vector})\n",
    "\n",
    "    print(f\"Добавлено {new_img} изображений\")\n",
    "\n",
    "    pk.dump(all_img_vector_and_guid, open(\"cache_data\\\\box_vector_NASNetLarge.pkl\", \"wb\"))                   #сохраняем обновленный бокс\n",
    "\n",
    "    all_only_vector = []\n",
    "\n",
    "    for img in all_img_vector_and_guid:                                              #от бокса оставляем только сами вектора для поиска расстояния\n",
    "        all_only_vector.append(np.array(img['vector']))\n",
    "    all_only_vector = np.array(all_only_vector)\n",
    "    all_only_vector = np.squeeze(all_only_vector)\n",
    "\n",
    "    print(f\"На создание/ обновление бокса потребовалось {start_box - time.time()}\")\n",
    "    print(\"Бокс обновлен, начинаем поиск похожих изображений\")\n",
    "\n",
    "    start_find = time.time()\n",
    "\n",
    "    dist = DistanceMetric.get_metric('euclidean')\n",
    "\n",
    "    result_temp = dict()                                                         \n",
    "\n",
    "    for i, distances in enumerate(dist.pairwise(all_only_vector)):\n",
    "\n",
    "        for eu_dist in distances:\n",
    "            if dist_min < eu_dist <= dist_max and list_path_all_img[i] != list_path_all_img[list(distances).index(eu_dist)]:   #не добавляем самого себя\n",
    "                path_origin = list_path_all_img[i]\n",
    "                name_origin = os.path.basename(path_origin).split('.')[0]\n",
    "\n",
    "                name_duplicate = os.path.basename(list_path_all_img[list(distances).index(eu_dist)]).split('.')[0]\n",
    "                \n",
    "                if name_origin not in result_temp.keys(): # and name_origin not in [a for tup in result_temp.values() for a in tup]: #and name_duplicate_size not in result_temp.values()\n",
    "                    result_temp.setdefault(name_origin, [name_duplicate])\n",
    "                \n",
    "                elif name_duplicate not in result_temp[name_origin]:\n",
    "                    result_temp[name_origin].append(name_duplicate)\n",
    "                    \n",
    "    list_all_similar = []\n",
    "\n",
    "    for origin, similars in result_temp.items():\n",
    "        pack_similar = [origin]\n",
    "        \n",
    "        for similar in similars:\n",
    "            pack_similar.append(similar)\n",
    "\n",
    "        sort_size_similar = sorted(pack_similar, key = lambda name: name, reverse = True)\n",
    "        similar_only_guid = [name.split('.')[0] for name in sort_size_similar]\n",
    "        list_all_similar.append(similar_only_guid)\n",
    "    \n",
    "    sort_len_similar_list_similar = sorted(list_all_similar, key = lambda len_similar: len(len_similar), reverse=True)\n",
    "\n",
    "    result_dict_all_sort = dict()\n",
    "\n",
    "    for similar in sort_len_similar_list_similar:\n",
    "        result_dict_all_sort.setdefault(similar[0], similar[1:])\n",
    "\n",
    "    print(f\"На поиск похожих изображений потребовалось {start_find - time.time()}\")\n",
    "\n",
    "    with open(os.path.join(path_result, 'result_duplicate-similar.json'), 'w') as file:\n",
    "        json.dump(result_dict_all_sort, file)\n",
    "\n",
    "    if test == True:\n",
    "        start_save_similar = time.time()\n",
    "        save_similar(path_result, list_path_all_img, result_dict_all_sort, all_img_guid)\n",
    "        print(f\"На сохранение похожих изображений в соответствующие лучшему изображению папки потребовалось {start_save_similar - time.time()}\")\n",
    "\n",
    "        start_glue = time.time()\n",
    "        #glue_image(path_result, model, dist)\n",
    "        print(f\"На сохранение похожих изображений в соответствующие лучшему изображению папки и их склейку потребовалось {start_glue - time.time()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    default_basepath = \"/home/dhauryk/TEMP/Friday\"\n",
    "    #default_basepath = \"D:\\\\All_full_images\"\n",
    "    default_path_result = \"/home/dhauryk/TEMP/temp\"\n",
    "    default_dist_min = 0\n",
    "    default_dist_max = 0.3\n",
    "    default_test = True\n",
    "    default_flag_some_dist = False\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Ищем дубликаты-похожие фото')\n",
    "    parser.add_argument('--basepath', default = default_basepath,\n",
    "                        help='Путь к папке с изображениями')\n",
    "    parser.add_argument('--path_result', default = default_path_result,\n",
    "                        help='Путь к папке для сохранения результата')\n",
    "    parser.add_argument('--dist_min', default = default_dist_min,\n",
    "                        help='Минимальная дистанция для отсечки between(0, dist_max)')\n",
    "    parser.add_argument('--dist_max', default = default_dist_max,\n",
    "                        help='Максимальная дистанция для отсечки between(dist_min, 7)')\n",
    "    parser.add_argument('--test', default = default_test,\n",
    "                        help='Сохранять ли похожие изображения для зрительного контроля и создавать ли склейки?')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    basepath = args.basepath\n",
    "    path_result = args.path_result\n",
    "    dist_min = args.dist_min\n",
    "    dist_max = args.dist_max\n",
    "    test = args.test\n",
    "\n",
    "    if default_flag_some_dist == True:\n",
    "        for dist in range(0, 50):\n",
    "            find_similar(basepath, f\"{path_result}  dist {dist/10} - {(dist + 1)/10}\", dist/10, (dist + 1)/10, test)\n",
    "    else:\n",
    "        find_similar(basepath, path_result, dist_min, dist_max, test)\n",
    "\n",
    "print(\"Завершено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
